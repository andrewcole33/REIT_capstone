{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "import warnings\n",
    "import os\n",
    "from fredapi import Fred\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2000,1,31)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMT = web.DataReader('AMT', 'av-daily', start = start, end = end, api_key = 'Y8YQFOIVHPA381U4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMT.drop(AMT.tail(5).index, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMT['mid'] = round((AMT['low']+AMT['high'])/2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMT = AMT[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMT.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AMT['mid'][:3500].as_matrix()\n",
    "test = AMT['mid'][3500:].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train = train.reshape(-1, 1)\n",
    "test = test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AMT)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smoothing_window_size = 875\n",
    "\n",
    "for di in range(0,2515,smoothing_window_size):\n",
    "    scaler.fit(train[di:di+smoothing_window_size,:])\n",
    "    train[di:di+smoothing_window_size,:] = scaler.transform(train[di:di+smoothing_window_size,:])\n",
    "\n",
    "# You normalize the last bit of remaining data\n",
    "scaler.fit(train[di+smoothing_window_size:,:])\n",
    "train[di+smoothing_window_size:,:] = scaler.transform(train[di+smoothing_window_size:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data \n",
    "train = train.reshape(-1)\n",
    "test = scaler.transform(test).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth data using exponential moving average\n",
    "EMA = 0.0\n",
    "gamma = 0.1\n",
    "for ti in range(3500):\n",
    "    EMA = gamma*train[ti] + (1-gamma)*EMA\n",
    "    train[ti] = EMA\n",
    "    \n",
    "all_mid_data = np.concatenate([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Unrolled index 0\n",
      "\tInputs:  [0.09116118 0.09795801 0.18099165 0.17986889 0.2645283 ]\n",
      "\n",
      "\tOutput: [0.31437966 0.26289052 0.18099165 0.16823266 0.25316912]\n",
      "\n",
      "\n",
      "Unrolled index 1\n",
      "\tInputs:  [0.17736569 0.18537089 0.16289249 0.16188201 0.24806233]\n",
      "\n",
      "\tOutput: [0.25029925 0.18537089 0.24056786 0.16823266 0.24429448]\n",
      "\n",
      "\n",
      "Unrolled index 2\n",
      "\tInputs:  [0.25029925 0.26289052 0.24056786 0.16823266 0.242967  ]\n",
      "\n",
      "\tOutput: [0.31437966 0.33660147 0.37574446 0.2514094  0.2688351 ]\n",
      "\n",
      "\n",
      "Unrolled index 3\n",
      "\tInputs:  [0.31437966 0.33660147 0.3119325  0.2514094  0.24429448]\n",
      "\n",
      "\tOutput: [0.31437966 0.4972903  0.3119325  0.2514094  0.2688351 ]\n",
      "\n",
      "\n",
      "Unrolled index 4\n",
      "\tInputs:  [0.36988565 0.39713717 0.37574446 0.31455562 0.25316912]\n",
      "\n",
      "\tOutput: [0.36988565 0.4972903  0.5529047  0.37000182 0.28470916]\n"
     ]
    }
   ],
   "source": [
    "#Use data generator to train model\n",
    "# outputs a set of unrolled batches (sequential)\n",
    "# each batch will have corresponding output batch\n",
    "\n",
    "class DataGeneratorSeq(object):\n",
    "\n",
    "    def __init__(self,prices,batch_size,num_unroll):\n",
    "        self._prices = prices\n",
    "        self._prices_length = len(self._prices) - num_unroll\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unroll = num_unroll\n",
    "        self._segments = self._prices_length //self._batch_size\n",
    "        self._cursor = [offset * self._segments for offset in range(self._batch_size)]\n",
    "\n",
    "    def next_batch(self):\n",
    "\n",
    "        batch_data = np.zeros((self._batch_size),dtype=np.float32)\n",
    "        batch_labels = np.zeros((self._batch_size),dtype=np.float32)\n",
    "\n",
    "        for b in range(self._batch_size):\n",
    "            if self._cursor[b]+1>=self._prices_length:\n",
    "                #self._cursor[b] = b * self._segments\n",
    "                self._cursor[b] = np.random.randint(0,(b+1)*self._segments)\n",
    "\n",
    "            batch_data[b] = self._prices[self._cursor[b]]\n",
    "            batch_labels[b]= self._prices[self._cursor[b]+np.random.randint(0,5)]\n",
    "\n",
    "            self._cursor[b] = (self._cursor[b]+1)%self._prices_length\n",
    "\n",
    "        return batch_data,batch_labels\n",
    "\n",
    "    def unroll_batches(self):\n",
    "\n",
    "        unroll_data,unroll_labels = [],[]\n",
    "        init_data, init_label = None,None\n",
    "        for ui in range(self._num_unroll):\n",
    "\n",
    "            data, labels = self.next_batch()    \n",
    "\n",
    "            unroll_data.append(data)\n",
    "            unroll_labels.append(labels)\n",
    "\n",
    "        return unroll_data, unroll_labels\n",
    "\n",
    "    def reset_indices(self):\n",
    "        for b in range(self._batch_size):\n",
    "            self._cursor[b] = np.random.randint(0,min((b+1)*self._segments,self._prices_length-1))\n",
    "\n",
    "\n",
    "\n",
    "dg = DataGeneratorSeq(train,5,5)\n",
    "u_data, u_labels = dg.unroll_batches()\n",
    "\n",
    "for ui,(dat,lbl) in enumerate(zip(u_data,u_labels)):   \n",
    "    print('\\n\\nUnrolled index %d'%ui)\n",
    "    dat_ind = dat\n",
    "    lbl_ind = lbl\n",
    "    print('\\tInputs: ',dat )\n",
    "    print('\\n\\tOutput:',lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
